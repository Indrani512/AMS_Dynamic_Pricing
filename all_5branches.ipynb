{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9b2b11-89e4-4593-9019-6faa06d23bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98964453-9ef3-4c25-b040-3acbcad3d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\indra\\OneDrive\\Desktop\\filtered_data_folder\\filtered_branches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8791b68-7367-496b-80f8-0e1ce4caa73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateCreated       0\n",
       "MoveDate          0\n",
       "MoveType          0\n",
       "MoveSize          0\n",
       "HourlyRate        0\n",
       "CrewSize          0\n",
       "Trucks            0\n",
       "Branch            0\n",
       "Source            0\n",
       "Current_Status    0\n",
       "BookStatus        0\n",
       "Lag_Days          0\n",
       "weekday           0\n",
       "is_weekend        0\n",
       "season            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ffd641-6239-41e3-bd66-71c3a780cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['MoveDate', 'Lag_Days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5325a865-3935-471f-bc86-5b2570efdb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateCreated       0\n",
       "MoveDate          0\n",
       "MoveType          0\n",
       "MoveSize          0\n",
       "HourlyRate        0\n",
       "CrewSize          0\n",
       "Trucks            0\n",
       "Branch            0\n",
       "Source            0\n",
       "Current_Status    0\n",
       "BookStatus        0\n",
       "Lag_Days          0\n",
       "weekday           0\n",
       "is_weekend        0\n",
       "season            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4a6457-3369-40db-b239-0556c204cdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318407, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3445fde-7e14-42d4-b718-ba915601a52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>MoveDate</th>\n",
       "      <th>MoveType</th>\n",
       "      <th>MoveSize</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>CrewSize</th>\n",
       "      <th>Trucks</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Source</th>\n",
       "      <th>Current_Status</th>\n",
       "      <th>BookStatus</th>\n",
       "      <th>Lag_Days</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09-01-2022 15:59</td>\n",
       "      <td>22-02-2022 00:00</td>\n",
       "      <td>Local</td>\n",
       "      <td>Apt 1 Bedroom</td>\n",
       "      <td>169.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>MobileAMSMainLead</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>No Book</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-01-2022 09:37</td>\n",
       "      <td>26-02-2022 00:00</td>\n",
       "      <td>Short Haul</td>\n",
       "      <td>House 3 Bedroom</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Houston</td>\n",
       "      <td>HAExactMatch</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>No Book</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-01-2022 12:24</td>\n",
       "      <td>08-02-2022 00:00</td>\n",
       "      <td>Local</td>\n",
       "      <td>House 3 Bedroom</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>GMB</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Booked</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-01-2022 13:43</td>\n",
       "      <td>27-01-2022 00:00</td>\n",
       "      <td>Long Distance</td>\n",
       "      <td>House 3 Bedroom</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>HAMarketMatch</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>No Book</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-01-2022 15:45</td>\n",
       "      <td>11-01-2022 00:00</td>\n",
       "      <td>Local</td>\n",
       "      <td>Storage</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Houston</td>\n",
       "      <td>pricingpagegoogledec2019CC</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Booked</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCreated          MoveDate       MoveType         MoveSize  \\\n",
       "0  09-01-2022 15:59  22-02-2022 00:00          Local    Apt 1 Bedroom   \n",
       "1  10-01-2022 09:37  26-02-2022 00:00     Short Haul  House 3 Bedroom   \n",
       "2  10-01-2022 12:24  08-02-2022 00:00          Local  House 3 Bedroom   \n",
       "3  10-01-2022 13:43  27-01-2022 00:00  Long Distance  House 3 Bedroom   \n",
       "4  10-01-2022 15:45  11-01-2022 00:00          Local          Storage   \n",
       "\n",
       "   HourlyRate  CrewSize  Trucks      Branch                      Source  \\\n",
       "0       169.0         3       1  Fort Worth           MobileAMSMainLead   \n",
       "1       159.0         2       1     Houston                HAExactMatch   \n",
       "2       159.0         3       1     Phoenix                         GMB   \n",
       "3       119.0         2       1     Phoenix               HAMarketMatch   \n",
       "4       199.0         3       1     Houston  pricingpagegoogledec2019CC   \n",
       "\n",
       "  Current_Status BookStatus  Lag_Days  weekday  is_weekend  season  \n",
       "0      Cancelled    No Book        43        1           0  Winter  \n",
       "1      Cancelled    No Book        46        5           1  Winter  \n",
       "2      Completed     Booked        28        1           0  Winter  \n",
       "3      Cancelled    No Book        16        3           0  Winter  \n",
       "4      Completed     Booked         0        1           0  Winter  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b522e4-7b75-4808-9e49-fcdb5b304c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>MoveDate</th>\n",
       "      <th>MoveType</th>\n",
       "      <th>MoveSize</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>CrewSize</th>\n",
       "      <th>Trucks</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Source</th>\n",
       "      <th>Current_Status</th>\n",
       "      <th>BookStatus</th>\n",
       "      <th>Lag_Days</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318402</th>\n",
       "      <td>27-11-2020 16:05</td>\n",
       "      <td>05-12-2020</td>\n",
       "      <td>Local</td>\n",
       "      <td>Apt 2 Bedroom or more</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Houston</td>\n",
       "      <td>pricingpagegoogledec2019</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>No Book</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318403</th>\n",
       "      <td>30-11-2020 11:45</td>\n",
       "      <td>19-12-2020</td>\n",
       "      <td>Local</td>\n",
       "      <td>Apt 1 Bedroom</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Booked</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318404</th>\n",
       "      <td>05-09-2020 14:35</td>\n",
       "      <td>05-10-2020</td>\n",
       "      <td>Long Distance</td>\n",
       "      <td>Apt 1 Bedroom</td>\n",
       "      <td>219.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Houston</td>\n",
       "      <td>A-PPC</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>No Book</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318405</th>\n",
       "      <td>16-11-2020 15:38</td>\n",
       "      <td>23-11-2020</td>\n",
       "      <td>Local</td>\n",
       "      <td>House 4 Bedroom or more</td>\n",
       "      <td>299.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>MobileAMSMainLead</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Booked</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318406</th>\n",
       "      <td>30-11-2020 18:16</td>\n",
       "      <td>01-12-2020</td>\n",
       "      <td>Local</td>\n",
       "      <td>Apt 1 Bedroom</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Houston</td>\n",
       "      <td>pricingpagegoogledec2019coupon</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>No Book</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateCreated    MoveDate       MoveType                 MoveSize  \\\n",
       "318402  27-11-2020 16:05  05-12-2020          Local    Apt 2 Bedroom or more   \n",
       "318403  30-11-2020 11:45  19-12-2020          Local            Apt 1 Bedroom   \n",
       "318404  05-09-2020 14:35  05-10-2020  Long Distance            Apt 1 Bedroom   \n",
       "318405  16-11-2020 15:38  23-11-2020          Local  House 4 Bedroom or more   \n",
       "318406  30-11-2020 18:16  01-12-2020          Local            Apt 1 Bedroom   \n",
       "\n",
       "        HourlyRate  CrewSize  Trucks      Branch  \\\n",
       "318402       159.0         3       1     Houston   \n",
       "318403       159.0         3       1     Phoenix   \n",
       "318404       219.0         4       1     Houston   \n",
       "318405       299.0         5       2  Fort Worth   \n",
       "318406       129.0         2       1     Houston   \n",
       "\n",
       "                                Source Current_Status BookStatus  Lag_Days  \\\n",
       "318402        pricingpagegoogledec2019      Cancelled    No Book         7   \n",
       "318403                           OTHER      Completed     Booked        18   \n",
       "318404                           A-PPC      Cancelled    No Book        29   \n",
       "318405               MobileAMSMainLead      Completed     Booked         6   \n",
       "318406  pricingpagegoogledec2019coupon      Cancelled    No Book         0   \n",
       "\n",
       "        weekday  is_weekend  season  \n",
       "318402        5           1  Winter  \n",
       "318403        5           1  Winter  \n",
       "318404        0           0    Fall  \n",
       "318405        0           0    Fall  \n",
       "318406        1           0  Winter  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3014b83-e69c-49e9-8d11-d7956111424a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateCreated        object\n",
       "MoveDate           object\n",
       "MoveType           object\n",
       "MoveSize           object\n",
       "HourlyRate        float64\n",
       "CrewSize            int64\n",
       "Trucks              int64\n",
       "Branch             object\n",
       "Source             object\n",
       "Current_Status     object\n",
       "BookStatus         object\n",
       "Lag_Days            int64\n",
       "weekday             int64\n",
       "is_weekend          int64\n",
       "season             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61dc577a-db0f-40b5-a947-e6f61db8b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DateCreated  MoveDate  MoveType  MoveSize  HourlyRate  CrewSize  Trucks  \\\n",
      "0        71017      5365         7         0       169.0         3       1   \n",
      "1        79661      6244        13         5       159.0         2       1   \n",
      "2        79718      1735         7         5       159.0         3       1   \n",
      "3        79747      6434        10         5       119.0         2       1   \n",
      "4        79793      2452         7         9       199.0         3       1   \n",
      "\n",
      "   Branch  Source  Current_Status  BookStatus  Lag_Days  weekday  is_weekend  \\\n",
      "0       1     204               4           1        43        1           0   \n",
      "1       2     172               4           1        46        5           1   \n",
      "2       4     155               5           0        28        1           0   \n",
      "3       4     173               4           1        16        3           0   \n",
      "4       2     303               5           0         0        1           0   \n",
      "\n",
      "   season  \n",
      "0       3  \n",
      "1       3  \n",
      "2       3  \n",
      "3       3  \n",
      "4       3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# List of categorical columns (object type)\n",
    "categorical_cols = ['DateCreated', 'MoveDate', 'MoveType', 'MoveSize', \n",
    "                    'Branch', 'Source', 'Current_Status', 'BookStatus','season']\n",
    "\n",
    "# Apply Label Encoding\n",
    "label_encoders = {} \n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])  # Transform categorical values to numerical\n",
    "    label_encoders[col] = le  # Store encoder for later use (inverse transform if needed)\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846088b1-1560-46c2-9bb3-c1ad95249bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318407, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea337c35-453c-4bf6-b7cc-2858e415cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import VAR\n",
    "import pickle\n",
    "\n",
    "# Assuming 'data' is your DataFrame and multiple columns are used as predictors\n",
    "time_column = \"MoveDate\"\n",
    "target_columns = [\"HourlyRate\", \"Trucks\"]  # Adjust for multiple time series\n",
    "\n",
    "# Convert date column to datetime format\n",
    "data[time_column] = pd.to_datetime(data[time_column])\n",
    "data.set_index(time_column, inplace=True)\n",
    "\n",
    "# Train the VAR model\n",
    "train_data = data[target_columns]\n",
    "\n",
    "# Define and fit the model\n",
    "model = VAR(train_data)\n",
    "model_fitted = model.fit(maxlags=15, ic='aic')  # Select lag order using AIC\n",
    "\n",
    "# Save the model\n",
    "with open(\"var_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_fitted, f)\n",
    "\n",
    "print(\"VAR model trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c59260a-367e-4846-8815-687ee816818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for HourlyRate: 48.146863201571605\n",
      "RMSE for Trucks: 0.17958120698047214\n"
     ]
    }
   ],
   "source": [
    "# Load the saved VAR model\n",
    "with open(\"var_model.pkl\", \"rb\") as f:\n",
    "    model_fitted = pickle.load(f)\n",
    "\n",
    "# Define forecasting horizon\n",
    "forecast_steps = 30  # Adjust as needed\n",
    "\n",
    "# Get the last observed values for forecasting\n",
    "input_data = train_data.values[-model_fitted.k_ar:]  # Use last k_ar observations\n",
    "\n",
    "# Make predictions\n",
    "forecast = model_fitted.forecast(y=input_data, steps=forecast_steps)\n",
    "\n",
    "# Convert forecast to DataFrame\n",
    "forecast_index = pd.date_range(start=train_data.index[-1], periods=forecast_steps + 1, freq=\"D\")[1:]\n",
    "forecast_df = pd.DataFrame(forecast, index=forecast_index, columns=target_columns)\n",
    "\n",
    "# Compute evaluation metrics (e.g., RMSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for col in target_columns:\n",
    "    actual = data[col].iloc[-forecast_steps:]  # Get actual values\n",
    "    predicted = forecast_df[col].values\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    print(f\"RMSE for {col}: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5cdd363-7c6e-4654-9680-f651d1f460c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mxnet-cu112 \n",
    "#!pip install gluonts\n",
    "#!pip install --upgrade mxnet==1.6.0\n",
    "#!pip install \"gluonts[torch]\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c116b99-e954-43d8-b151-a16d29a54a69",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.mx.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "from mxnet import gpu\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Target' is the column to predict\n",
    "target_column = \"Target\"\n",
    "time_column = \"DateCreated\"\n",
    "\n",
    "# Convert the data to a GluonTS ListDataset format\n",
    "training_data = ListDataset(\n",
    "    [{\n",
    "        \"start\": pd.to_datetime(data[time_column].min()),\n",
    "        \"target\": data[target_column].values\n",
    "    }],\n",
    "    freq=\"D\"  # Adjust based on your dataset's frequency\n",
    ")\n",
    "\n",
    "# Define and train the DeepAR model\n",
    "estimator = DeepAREstimator(\n",
    "    freq=\"D\",\n",
    "    prediction_length=30,  # Adjust prediction horizon as needed\n",
    "    trainer=Trainer(epochs=10, ctx=gpu() if gpu().device_count() > 0 else \"cpu\")\n",
    ")\n",
    "predictor = estimator.train(training_data)\n",
    "\n",
    "# Generate forecasts\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=training_data, predictor=predictor, num_samples=100\n",
    ")\n",
    "\n",
    "# Convert iterator objects to lists\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = Evaluator()\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts))\n",
    "print(\"Evaluation Metrics:\", agg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "423a4b45-9c68-478c-9ef3-12b16f51c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (254725, 13), X_test shape: (63682, 13)\n",
      "y_train shape: (254725,), y_test shape: (63682,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = 'HourlyRate'  # Change this to your actual target column\n",
    "X = data.drop(columns=[target_col])  # Features\n",
    "y = data[target_col]  # Target variable\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the splits\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02913fed-b66d-4d99-b229-5c759f1c6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete. Saved as 'lightgbm_model.pkl'\n",
      "RMSE on train data: 16.035977428273423\n",
      "RMSE on test data: 15.698927915096128\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages (uncomment if needed)\n",
    "# !pip install lightgbm pandas numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Prepare LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Define model parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "model = lgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "# Save the model\n",
    "with open(\"lightgbm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model training complete. Saved as 'lightgbm_model.pkl'\")\n",
    "\n",
    "# Load the model for validation on train data\n",
    "with open(\"lightgbm_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Make predictions on train data\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate the model on train data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(f\"RMSE on train data: {rmse_train}\")\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE on test data: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d20323-e949-4100-be45-208a1e2198f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 highest difference values between Predicted vs Actual:\n",
      "                               Actual   Predicted  Difference\n",
      "MoveDate                                                     \n",
      "1970-01-01 00:00:00.000005394   955.0  356.887827  598.112173\n",
      "1970-01-01 00:00:00.000006447   100.0  494.820781  394.820781\n",
      "1970-01-01 00:00:00.000006019   540.0  205.342479  334.657521\n",
      "1970-01-01 00:00:00.000002090   100.0  417.170047  317.170047\n",
      "1970-01-01 00:00:00.000000190   100.0  413.570937  313.570937\n",
      "1970-01-01 00:00:00.000001815   500.0  220.346680  279.653320\n",
      "1970-01-01 00:00:00.000003313   609.0  360.807208  248.192792\n",
      "1970-01-01 00:00:00.000006023    20.0  265.209255  245.209255\n",
      "1970-01-01 00:00:00.000000152   400.0  640.644396  240.644396\n",
      "1970-01-01 00:00:00.000007133   159.0  395.241804  236.241804\n",
      "1970-01-01 00:00:00.000004459   111.0  320.126238  209.126238\n",
      "1970-01-01 00:00:00.000002075   398.0  195.352351  202.647649\n",
      "1970-01-01 00:00:00.000006905   153.0  353.115001  200.115001\n",
      "1970-01-01 00:00:00.000003021   350.0  150.582383  199.417617\n",
      "1970-01-01 00:00:00.000006003   350.0  152.522702  197.477298\n",
      "1970-01-01 00:00:00.000006904   379.0  181.684639  197.315361\n",
      "1970-01-01 00:00:00.000005010   450.0  253.236832  196.763168\n",
      "1970-01-01 00:00:00.000000190   350.0  155.245311  194.754689\n",
      "1970-01-01 00:00:00.000000968   549.0  359.174565  189.825435\n",
      "1970-01-01 00:00:00.000004797     3.0  188.315714  185.315714\n"
     ]
    }
   ],
   "source": [
    "# Compute absolute differences between actual and predicted values\n",
    "test_results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "test_results[\"Difference\"] = abs(test_results[\"Actual\"] - test_results[\"Predicted\"])\n",
    "\n",
    "# Get the top 20 highest differences\n",
    "top_20_high_diff = test_results.nlargest(20, \"Difference\")\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 20 highest difference values between Predicted vs Actual:\")\n",
    "print(top_20_high_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab40d4a8-79e0-4a08-91f6-c45c6721b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete. Saved as 'random_forest_model.pkl'\n",
      "RMSE on test data: 14.744360495473963\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "#!pip install pandas numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Train RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model training complete. Saved as 'random_forest_model.pkl'\")\n",
    "\n",
    "# Load the model for testing\n",
    "with open(\"random_forest_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE on test data: {rmse}\")\n",
    "\n",
    "# How to Run:\n",
    "# 1. Ensure 'your_data.csv' exists with relevant feature columns and 'Target'.\n",
    "# 2. Run this script to train and save the model.\n",
    "# 3. Load the saved model to make predictions and evaluate on test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f7f463c-1af0-43c6-b94a-de498fe8c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoders saved successfully as 'label_encoders.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample dataset (replace with your actual dataset)\n",
    "data = pd.read_csv(r\"C:\\Users\\indra\\OneDrive\\Desktop\\filtered_data_folder\\filtered_branches.csv\")\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [\"MoveType\", \"MoveSize\", \"Branch\", \"Source\", \"Current_Status\", \"BookStatus\", \"season\"]\n",
    "#df[\"MoveDate\"] = pd.to_datetime(df[\"MoveDate\"]).map(pd.Timestamp.toordinal)\n",
    "\n",
    "\n",
    "# Create label encoders dictionary\n",
    "label_encoders = {}\n",
    "\n",
    "# Fit and transform each categorical column\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])  # Fit and transform dataset\n",
    "    label_encoders[col] = le  # Store label encoder\n",
    "\n",
    "# Save label encoders to a pickle file\n",
    "with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print(\"Label encoders saved successfully as 'label_encoders.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "278d7d6c-2b51-4df2-a278-94f48ec52913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoders saved as 'label_encoders.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print(\"Label encoders saved as 'label_encoders.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5463cba-4f6e-4df4-93ba-c1ee98cb7c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 205.48\n"
     ]
    }
   ],
   "source": [
    "def predict_new_data(new_data):\n",
    "    # Convert input to DataFrame\n",
    "    df_input = pd.DataFrame([new_data])\n",
    "\n",
    "    # Convert date columns to ordinal format (if used in training)\n",
    "    df_input[\"DateCreated\"] = pd.to_datetime(df_input[\"DateCreated\"]).map(pd.Timestamp.toordinal)\n",
    "\n",
    "    # Remove MoveDate if it wasn't used during training\n",
    "    df_input.drop(columns=[\"MoveDate\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Encode categorical variables\n",
    "    for col in df_input.select_dtypes(include=[\"object\"]).columns:\n",
    "        if col in label_encoders:\n",
    "            try:\n",
    "                df_input[col] = label_encoders[col].transform(df_input[col])\n",
    "            except ValueError:\n",
    "                print(f\"Error: Unseen category in {col}: {df_input[col].values}\")\n",
    "                return None  # Stop prediction if an unseen category is found\n",
    "\n",
    "    # Ensure the input columns match the training feature set\n",
    "    df_input = df_input[X_train.columns]\n",
    "\n",
    "    # Predict output\n",
    "    prediction = model.predict(df_input)\n",
    "    return prediction[0]\n",
    "# Example Input (Fixed Format)\n",
    "new_input = {\n",
    "    \"DateCreated\": \"2025-03-11 11:51:00\",  # Assuming this is a date feature\n",
    "    \"MoveDate\": \"2025-03-26\t 00:00\",  # Assuming this is a date feature\n",
    "    \"MoveType\": \"Local\",  # Categorical\n",
    "    \"MoveSize\": \"Apt 1 Bedroom\",  # Numeric\n",
    "    \"CrewSize\": 4,  # Numeric\n",
    "    \"Trucks\": 1,  # Numeric\n",
    "    \"Branch\": \"Houston\",  # Categorical\n",
    "    \"Source\": \"MobileAMSMainLead\",  # Categorical\n",
    "    \"Current_Status\": \"Completed\",  # Categorical\n",
    "    \"BookStatus\": \"Booked\", \n",
    "    \"Lag_Days\": 3, # Categorical\n",
    "    \"weekday\": 5,  # Numeric\n",
    "    \"is_weekend\": 0,  # Binary (0 = No, 1 = Yes)\n",
    "    \"season\": \"Spring\"  # Categorical\n",
    "}\n",
    "\n",
    "predicted_value = predict_new_data(new_input)\n",
    "print(f\"Predicted value: {predicted_value}\")\n",
    "\n",
    "# Save label encoders as pickle file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf6897e-8866-4012-903c-1768e8a1efce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
